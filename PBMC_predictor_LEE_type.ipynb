{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Data preparation and model training for scPheno"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- __Data preparation__: scPheno accept three kinds of input files. \n",
                "    1. Expression matrix in the MTX format, where rows are cells and columns are genes.\n",
                "    2. Cell type/state annotation in the tsv/csv format, where a row is the annotation of one cell.\n",
                "    3. Phenotypic condition annotation in the tsv/csv format, where a row is the annotation of one cell.\n",
                "\n",
                "    This tutorial uses the COVID-19 dataset provided in the paper [Jeong Seok Lee, et al, 2020](https://doi.org/10.1126/sciimmunol.abd1554). The data in the H5DF format can be downloaded from [here](https://s3.us-west-2.amazonaws.com/atlas.fredhutch.org/data/hutch/covid19/downloads/lee_2020_processed.HDF5). Users can check the R script prepare_data.R In the [Lee_data2](https://github.com/ZengFLab/scPheno/tree/main/Lee_data2) directory for the instructions on preparing the required input files for the Lee's data.\n",
                "\n",
                "- __Model training__: The following command is used to train a scPheno model for the Lee's data. Users can run  `python scPheno.py -h`  for more details on the scPheno parameters.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%bash\n",
                "\n",
                "python scPheno.py --sup-data-file ~/Project/Lee_data2/lee_dataset.mtx \\\n",
                "                        --sup-label-file ~/Project/Lee_data2/lee_dataset_label_text.txt \\\n",
                "                        --sup-condition-file ~/Project/Lee_data2/lee_dataset_disease_text.txt \\\n",
                "                        -lr 0.00001 \\\n",
                "                        -n 30 \\\n",
                "                        -bs 1000 \\\n",
                "                        --aux-loss \\\n",
                "                        --validation-fold 10 \\\n",
                "                        --cuda \\\n",
                "                        --save-model Lee_model_type.pth\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Compute the cell state-phenotype embedding of cells"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In general, scPheno can compute three kinds of low-dimension cell embeddings.\n",
                "- The joint cell embedding with the consideration of transcriptional variations in both cell type/state and phenotype.\n",
                "- The cell embedding where only transcriptional variations in cell type/state are of interest.\n",
                "- The cell embedding where only transcriptional variations in cell phenotype are of interest.\n",
                "\n",
                "\n",
                "With the trained model and the expression matrix of cells in the MTX format, users can use the function __latent_embedding__ to compute the above three kinds of cell embeddings. The following example demonstrates the steps to compute the cell embeddings for the Lee's data.\n",
                "\n",
                "First, the required Python packages are imported."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
                    ]
                }
            ],
            "source": [
                "%matplotlib inline\n",
                "import matplotlib.pyplot as plt\n",
                "from sklearnex import patch_sklearn\n",
                "patch_sklearn()\n",
                "\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy.io import mmread\n",
                "from collections import Counter\n",
                "\n",
                "from scPheno import scPheno\n",
                "from utils.scdata_cached import setup_data_loader, SingleCellCached, transform_label2class, label2class_encoder, transform_class2label\n",
                "\n",
                "import torch\n",
                "import torch.nn.functional as ft\n",
                "from torch.utils.data import DataLoader\n",
                "\n",
                "import pyro.distributions as dist\n",
                "\n",
                "from sklearn.preprocessing import StandardScaler, Normalizer, OneHotEncoder\n",
                "from sklearn.decomposition import PCA\n",
                "from sklearn.metrics import accuracy_score, f1_score, ConfusionMatrixDisplay\n",
                "\n",
                "import umap"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Second, the trained model and the expression matrix are loaded.\n",
                "\n",
                "- __batch_size__: In the application phase, batch_size is not needed to be the same as the batch_size in the training phase. Users can use a large batch size in the application phase for high-speed processing.\n",
                "- __use_float64__: This option is useful when processing an extremely large dataset where the likelihood score can be overflowed if 32-bit float precision is used. This option shall be consistent in the training phase and the application phase. The error will occur if the model is trained with 32-bit float precision but users use it to process data in the 64-bit float precision and vice verse. \n",
                "- __use_cuda__: This option shall keep the same as the usage of use_cuda option in the training phase. This option ensures that the model and data are on the same device. Specifically, if the model is trained on a GPU device, the data shall be loaded onto the GPU device. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "ModelPath = 'Lee_model_type.pth'\n",
                "DataPath='/home/zengbio/Project/Lee_data2/lee_dataset.mtx'\n",
                "LabelPath=None\n",
                "ConditionPath=None\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load model\n",
                "model = torch.load(ModelPath)\n",
                "\n",
                "batch_size = 100\n",
                "\n",
                "use_float64 = False\n",
                "use_cuda = True"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "array(['COVID-19', 'healthy', 'other'], dtype=object)"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "model.cond2index.classes_"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 53,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load data\n",
                "data_cached = SingleCellCached(DataPath, LabelPath, ConditionPath, model.class2label, model.index2cond, 'condition', use_cuda=False, use_float64 = use_float64)\n",
                "data_loader = DataLoader(data_cached, batch_size = batch_size, shuffle = False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In the default setting, the latent dimension of scPheno is 50. To obtain the 2D visualization of cell embeddings, users should use [UMAP](https://umap-learn.readthedocs.io/en/latest/index.html) on the low-dimension embeddings provided by scPheno. Users can check the R script plot_scp_umap.R in the [Lee_data2](https://github.com/ZengFLab/scPheno/tree/main/Lee_data2) directory for the instructions on how to add the 2D positions to the Seurat object for visualization."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 54,
            "metadata": {},
            "outputs": [],
            "source": [
                "# predict conditions\n",
                "embeds = []\n",
                "scores = []\n",
                "\n",
                "embeds_state = []\n",
                "embeds_condition = []\n",
                "# use the appropriate data loader\n",
                "for xs,ys,ks in data_loader:\n",
                "    # use classification function to compute all predictions for each batch\n",
                "    if use_cuda:\n",
                "        xs = xs.cuda()\n",
                "\n",
                "    zs = model.latent_embedding(xs)\n",
                "    _, kscores = model.predicted_condition(xs)\n",
                "\n",
                "    zs_state = model.latent_embedding(xs, use_state=True, use_condition=False)\n",
                "    zs_condition = model.latent_embedding(xs, use_state=False, use_condition=True)\n",
                "\n",
                "    if use_cuda:\n",
                "        zs = zs.cpu().detach().numpy()\n",
                "        zs_state = zs_state.cpu().detach().numpy()\n",
                "        zs_condition = zs_condition.cpu().detach().numpy()\n",
                "        kscores = kscores.cpu().detach().numpy()\n",
                "    else:\n",
                "        zs = zs.detach().numpy()\n",
                "        zs_state = zs_state.detach().numpy()\n",
                "        zs_condition = zs_condition.detach().numpy()\n",
                "        kscores = kscores.detach().numpy()\n",
                "\n",
                "    embeds.append(zs)\n",
                "    embeds_state.append(zs_state)\n",
                "    embeds_condition.append(zs_condition)\n",
                "    scores.append(kscores)\n",
                "\n",
                "embeds = np.concatenate(embeds, axis=0)\n",
                "embeds_state = np.concatenate(embeds_state, axis=0)\n",
                "embeds_condition = np.concatenate(embeds_condition, axis=0)\n",
                "scores = np.concatenate(scores, axis=0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "%%time\n",
                "pos = umap.UMAP(metric = 'cosine').fit_transform(embeds)\n",
                "pos_state = umap.UMAP(metric = 'cosine').fit_transform(embeds_state)\n",
                "pos_condition = umap.UMAP(metric = 'cosine').fit_transform(embeds_condition)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 57,
            "metadata": {},
            "outputs": [],
            "source": [
                "np.savetxt('/home/zengbio/Project/Lee_data2/lee_dataset_umap.txt', pos, delimiter=',')\n",
                "np.savetxt('/home/zengbio/Project/Lee_data2/lee_dataset_umap_state.txt', pos_state, delimiter=',')\n",
                "np.savetxt('/home/zengbio/Project/Lee_data2/lee_dataset_umap_condition.txt', pos_condition, delimiter=',')\n"
            ]
        }
    ],
    "metadata": {
        "interpreter": {
            "hash": "705d2180a8d3806c011eeb980cdb14749c2bbbebf661a11693d6315c18f55427"
        },
        "kernelspec": {
            "display_name": "Python 3.9.12 ('pyro')",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.12"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
